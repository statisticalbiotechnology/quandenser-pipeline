\documentclass[11pt]{article}
\usepackage[margin=2cm,a4paper]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{authblk}
\usepackage{float}

\usepackage[outdir=./img/]{epstopdf}
\usepackage{epsfig}
\usepackage{url}
\usepackage[nomarkers,nolists,tablesfirst]{endfloat}

\usepackage{xr}
\externaldocument{supplement}
\usepackage{tikz}
\usetikzlibrary{fit,positioning}
\usetikzlibrary{arrows}

\setlength\parindent{0pt}

\input{./title.tex}

\begin{document}

\maketitle

{ {\bf Running Title -- } Parallelization and containerization of quantitative protoeomics data processing pipelines}

\begin{abstract}
The methods for processing shotgun proteomics data are not always straight forward to operate, and sometimes need manual intervention. This problem is exacerbate due to a preference toward UNIX among bioinformatician software developers, while instrument manufacturerers' with few exceptions operate under Windows. In practice, this means that many mass spectrometry labs use Windows computers just for making the format conversion. This also means that there will be software environment issues. Containerization enables installation of software into a virtual container environment, in a so-called container, as opposed to into a particular computer. The container can be distributed, while guaranteed to execute the exact same way regardless of operating system. In this paper we use \textit{Singularity} to contain a novel method developed in out lab, \textit{Quandenser} (QUANtification by Distillation for ENhanced Singals with Error Regulation), that increase the sensitivity of the LFQ analysis pipeline. This pipeline incorporates multiple processing steps, coded in separate executables. Amongs other tools it contains Dinosaur, MaRaCluster, Crux, qvality and Triqler. To facilitate the installation of the method, all these components are placed in the Singularity container. To further facilitate the processing we used a workflow managing system, \textit{NextFlow}. We benchmark our method against established protein quantification method, \textit{MaxQuant} using \textit{Latosinska} and \textit{iRPG} datasets and find that our method has superior computational time. In addition, it can be used in High Performance Computing clusters. Lastly, features for processing a novel scan method called \textit{BoxCar} has also been incorporated into our processing pipeline. [Fundera pa avrundning]



\end{abstract}

\section*{Introduction}

Mass spectrometry-based proteomics is currently seen as the most comprehensive technique to analyze protein content in biological samples. Modern MS generate vast amounts of data and the analysis of such data is generally considered as a bottleneck. This has its reasons. The methods for processing the data are complex and are not always straight forward to operate, and sometimeds need manual intervention. As it is hard to recreate the exact software environment used during processing, many results produced with mass spectrometers cannot be accurately reproduced outside of the lab where it was initially generated.

The seamingly ever increasing performance of each generation of mass spectrometry equipment drives both sample sizes and the number of spectra per sample in a manner that the frequently single processr implemented approaches to data processing has a hard time to keep up.

There is also a mismatch between the bioinformaticians who often develop methods operating under Unix, and the fact that the instrument manufacturers' software with few exception operate under Windows. In practice this means that many mass spectrometry labs keep them selves with Windows computers, just for making format conversions between vendor specific raw file formats and non-proprietary file formats that can be read under windows.

The proteowizard community have created an windows executable that does such conversions. The system can be executed under the windows emulation program wine, however, the installation process is complicated and such installation are brittle and stop working over time.

New technology, so called containerization, provides means to install software, not into a particular computer, but into a virtual container environment, in a so-called container. The container can be distributed to several separate computers, yet is guaranteed to execute in the exact same way regardless of the operating system. There are several such containerization techniques available. The perhaps most popular one, docker, have a wide variety of available libraries of containers, and e.g. biocontainers\cite{}. However, docker containers, due to their nature, are executed with systems administrator privileges, and could be utilized for malicious purpose.  In this work we will focus on one named \textit{Singularity}, as it does not execute under root privileges and hence is the preferred solution of most computer cluster and High Performance Computing (HPC) clusters, particularly the ones in an academic environment.

Recently, the proteowizard comunity developed a docker-container for the wine implementation of msconvert (\url{https://hub.docker.com/r/chambm/pwiz-skyline-i-agree-to-the-vendor-licenses/}). This is tremendiously helpful, as it enables linux developers to produce piplines that can operate from beginning to end inside a linux environment, or even an HPC environment.

We recently introduced a new method, {\em Quandenser} (QUANtification by
Distillation for ENhanced Signals with Error Regulation), that increase the sensitivity of the LFQ
analysis pipeline. Just as any proteomics data analysis method, the processing consist of multiple steps, coded in separate executables. Among other tools it contains Dinosaur\cite{teleman2016dinosaur} for feature finding, MaRaCluster\cite{the2016maracluster} for clustering, Crux\cite{mcilwain2014} for database searching, and qvality\cite{kall2008non} as well as Triqler\cite{the2018integrated} for error assesments. To facilitate the installation of the method we placed these components in a Singularity container.

To further facilitate the processing we used a workflow managing system, deals with how different pieces of dependent software can be consequently executed in a particular environment. Again, there are several workflow managers available, but the one used was \textit{NextFlow}\cite{di2017nextflow}.

Quandenser condenses the quantification data by applying
unsupervised clustering on both MS1 and MS2 level and thereby paves the way for
a quantification-first approach. The algorithm combines the unknowns from both
levels into a condensed set of MS1 features and MS2 spectra that are likely to
be interesting for further investigation. Specifically, Quandenser incorporates
MBR for MS1 features to increase sensitivity and uses MS2 spectrum clustering
to decrease the number of spectra to be searched. Importantly, it also provides
{\em feature-feature match} error rates which can be used as input to Triqler
to account for the errors as a result of the MBR step.



\section*{Methods}

\subsection*{Data sets}

Three data sets were tested with the pipeline

\begin{table}[!h]
  \caption{{\textbf{Data sets}}}
  \label{table:datasets}
\begin{center}
\begin{tabular}{ccccc}
PRIDE id & Description & Amount of files & Size of data set \\ \hline \hline
PXD001474 & Latosinska & 8 RAW files & 10.2 Gb \\
PXD002170 & Bracht & 27 RAW files & 14.8 Gb  \\
PXD009348 & Boxcar & 168 RAW files & 163.2 Gb & \\
\end{tabular}
\end{center}
\end{table}

\section*{Results}

\subsection*{Parallelization}
In order to further reduce the running time we investigated the possibilities to parallelize the processing within quandenser. Particularly we performed the following optimizations:
\begin{itemize}
  \item The conversion of each run from raw file-format into mzML-format is an embarisingly parallalezible problem, in that each file can be processed in independent proceses. We henced just enabled parallel processing by implementing the conversion process as a nextflow node.
  \item The initial feature finding with Dinosaur\cite{teleman2016dinosaur} can be done independently for each file. Again we could parallize by just putting this into a separate nextflow node.
  \item Quandenser uses a minimum spanning tree strategy \cite{rost2016tric} to align the retention times of the different mass spectrometry runs. This makes an internal dependency structure. Every node in the minimum spanning tree will have to be aligned together with its sub-nodes, so the alignment process is done from the leafs inwards to the trunk.  However, at every level of the tree each branch can be processed independently. We have hence enabled individual processes to handle the alignment of every sub tree.
  \item FIXME: complete this list
\end{itemize}

\subsection*{Run time comparison}

To demonstrate the processing speed of the quandenser pipeline we processed a couple of large-scale data sets. We compared the processing time some different platform needed to complete the processing of the FIXME dataset.
\begin{table}[!h]
  \begin{center}
  \caption{\textbf{Comparison of run time between the different quantification platforms reported in wall time.}}
  \label{table:walltime}
\begin{tabular}{lcccccc}
& QP parallel (local) & QP non-parallel (local) & QP parallel (HPC) & QP non-parallel (HPC) & MaxQuant & OpenMS \\ \hline \hline
BoxCar Plasma & X & X & X & X & X & X \\
Bracht & 1h 43m & 1h 56m & 2h 40m & 2h 38m & X & X \\
Latosinska & 1h 14m & 1h 27m & 1h 52m & 2h 11m & X & X \\
\end{tabular}
\end{center}
\end{table}

\begin{table}
  \caption{\textbf{Comparison of run time between the different quantification platforms reported in cpu time.}}
  \label{table:cputime}
\begin{tabular}{lcccc}
& Quandenser HPC & Quandenser single node & MaxQuant & OpenMS \\
BoxCar Plasma & 2.23 h & X & X & N/A \\
Bracht &  & &&  \\
Latosinska & &&& \\
\end{tabular}

\end{table}


\subsection*{User Interface}

To facilitate the operation of quandenser, we have provided quandenser with a user interface. A couple of notable features of the user interface are FIXME.

\section*{Discussion}

Will Podman rock our world?

%Interesting discussion. Developer of Singularity chimes in on Podman Github
%https://github.com/containers/libpod/issues/3017

\bibliographystyle{plain}
\bibliography{pipeline}

\end{document}
